{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xB9-iQ4jfjgI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from statistics import mean\n",
    "import pickle\n",
    "import random\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "\n",
    "import time\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8DjCi5CzZxMy"
   },
   "outputs": [],
   "source": [
    "useSyntheticData = False\n",
    "\n",
    "#Nethealt = 4, synthetic = 5\n",
    "n_types = 4\n",
    "n_epoch = 1\n",
    "seq_len = 750\n",
    "batch_size = 10\n",
    "hidden_size = 64\n",
    "# RELU | SOFTPLUS | SOFTPLUS_SCALE\n",
    "transform_fun = 'SOFTPLUS_SCALE'\n",
    "# W2V = 2, GCN = 1\n",
    "number_of_embedding_features = 1\n",
    "number_of_spatio_features = 1\n",
    "# p = 1 for GCN and W2V\n",
    "windows_p = 3\n",
    "\n",
    "use_data_from_files = True \n",
    "\n",
    "# NN | GCN | TGCN | W2V | TW2V\n",
    "model = 'TGCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "MFuEwU0Eflaz",
    "outputId": "d5f81429-5ac8-4206-8361-5aebf4a5b1b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochtime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>insession</th>\n",
       "      <th>studyweek</th>\n",
       "      <th>studyday</th>\n",
       "      <th>egoid</th>\n",
       "      <th>egoconf</th>\n",
       "      <th>alterid</th>\n",
       "      <th>alterconf</th>\n",
       "      <th>outgoing</th>\n",
       "      <th>iphone</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>eventtypedetail</th>\n",
       "      <th>messagetype</th>\n",
       "      <th>duration</th>\n",
       "      <th>length</th>\n",
       "      <th>bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420088400000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>27169</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2250922</td>\n",
       "      <td>0.6</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420088401000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>738850</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1420088403000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>738850</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1420088405000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>19538</td>\n",
       "      <td>0.95</td>\n",
       "      <td>270980</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1420088406000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>738850</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1423622182000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:22</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>96689</td>\n",
       "      <td>0.95</td>\n",
       "      <td>345868</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1423622184000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:24</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>57697</td>\n",
       "      <td>0.95</td>\n",
       "      <td>828541</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>1423622185000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:25</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>57697</td>\n",
       "      <td>0.95</td>\n",
       "      <td>828541</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>1423622186000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:26</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>29232</td>\n",
       "      <td>0.95</td>\n",
       "      <td>286474</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>SM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>1423622189000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:29</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>96689</td>\n",
       "      <td>0.95</td>\n",
       "      <td>345868</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             epochtime        date      time dayofweek insession  studyweek  \\\n",
       "0        1420088400000  2015-01-01  00:00:00  Thursday        No        -33   \n",
       "1        1420088401000  2015-01-01  00:00:01  Thursday        No        -33   \n",
       "2        1420088403000  2015-01-01  00:00:03  Thursday        No        -33   \n",
       "3        1420088405000  2015-01-01  00:00:05  Thursday        No        -33   \n",
       "4        1420088406000  2015-01-01  00:00:06  Thursday        No        -33   \n",
       "...                ...         ...       ...       ...       ...        ...   \n",
       "1048570  1423622182000  2015-02-10  21:36:22   Tuesday        No        -27   \n",
       "1048571  1423622184000  2015-02-10  21:36:24   Tuesday        No        -27   \n",
       "1048572  1423622185000  2015-02-10  21:36:25   Tuesday        No        -27   \n",
       "1048573  1423622186000  2015-02-10  21:36:26   Tuesday        No        -27   \n",
       "1048574  1423622189000  2015-02-10  21:36:29   Tuesday        No        -27   \n",
       "\n",
       "         studyday  egoid  egoconf  alterid  alterconf outgoing  iphone  \\\n",
       "0            -227  27169     0.95  2250922        0.6       No       1   \n",
       "1            -227  96184     0.95   738850        0.7       No       1   \n",
       "2            -227  96184     0.95   738850        0.7       No       1   \n",
       "3            -227  19538     0.95   270980        0.5       No       1   \n",
       "4            -227  96184     0.95   738850        0.7       No       1   \n",
       "...           ...    ...      ...      ...        ...      ...     ...   \n",
       "1048570      -187  96689     0.95   345868        0.3      Yes       1   \n",
       "1048571      -187  57697     0.95   828541        0.5       No       1   \n",
       "1048572      -187  57697     0.95   828541        0.5       No       1   \n",
       "1048573      -187  29232     0.95   286474        0.7      Yes       1   \n",
       "1048574      -187  96689     0.95   345868        0.3      Yes       1   \n",
       "\n",
       "        eventtype eventtypedetail messagetype  duration  length  bytes  \n",
       "0             SMS              iM         NaN       NaN    13.0    NaN  \n",
       "1        WhatsApp              DM           T       NaN     1.0    NaN  \n",
       "2        WhatsApp              DM           T       NaN     1.0    NaN  \n",
       "3             SMS              iM         NaN       NaN    12.0    NaN  \n",
       "4        WhatsApp              DM           T       NaN     2.0    NaN  \n",
       "...           ...             ...         ...       ...     ...    ...  \n",
       "1048570       SMS              iM         NaN       NaN     6.0    NaN  \n",
       "1048571       SMS              iM         NaN       NaN    26.0    NaN  \n",
       "1048572       SMS              iM         NaN       NaN     8.0    NaN  \n",
       "1048573       SMS              SM         NaN       NaN     9.0    NaN  \n",
       "1048574       SMS              iM         NaN       NaN    13.0    NaN  \n",
       "\n",
       "[1048575 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(useSyntheticData):\n",
    "  events_df = pd.read_csv('./social-interactions/events_syn.csv')\n",
    "else:\n",
    "  events_df = pd.read_csv('./social-interactions/events.csv')  \n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eYXlXRlzfrhO"
   },
   "outputs": [],
   "source": [
    "events_df = events_df.sort_values(by=['epochtime'], ascending=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PsoMwjaTPMEg"
   },
   "outputs": [],
   "source": [
    "if('_id' not in events_df.columns):\n",
    "  events_df['_id'] = events_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "O0-gKBc2lQVc",
    "outputId": "8d919bfb-ad4a-4145-d124-3e0641acb305"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>epochtime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>insession</th>\n",
       "      <th>studyweek</th>\n",
       "      <th>studyday</th>\n",
       "      <th>egoid</th>\n",
       "      <th>egoconf</th>\n",
       "      <th>...</th>\n",
       "      <th>alterconf</th>\n",
       "      <th>outgoing</th>\n",
       "      <th>iphone</th>\n",
       "      <th>eventtype</th>\n",
       "      <th>eventtypedetail</th>\n",
       "      <th>messagetype</th>\n",
       "      <th>duration</th>\n",
       "      <th>length</th>\n",
       "      <th>bytes</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1420088400000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>27169</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1420088401000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1420088403000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1420088405000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>19538</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1420088406000</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:06</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>-33</td>\n",
       "      <td>-227</td>\n",
       "      <td>96184</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>DM</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1048570</td>\n",
       "      <td>1423622182000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:22</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>96689</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1048571</td>\n",
       "      <td>1423622184000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:24</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>57697</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>1048572</td>\n",
       "      <td>1423622185000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:25</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>57697</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>1048573</td>\n",
       "      <td>1423622186000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:26</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>29232</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>SM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>1048574</td>\n",
       "      <td>1423622189000</td>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>21:36:29</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>-27</td>\n",
       "      <td>-187</td>\n",
       "      <td>96689</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>SMS</td>\n",
       "      <td>iM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index      epochtime        date      time dayofweek insession  \\\n",
       "0              0  1420088400000  2015-01-01  00:00:00  Thursday        No   \n",
       "1              1  1420088401000  2015-01-01  00:00:01  Thursday        No   \n",
       "2              2  1420088403000  2015-01-01  00:00:03  Thursday        No   \n",
       "3              3  1420088405000  2015-01-01  00:00:05  Thursday        No   \n",
       "4              4  1420088406000  2015-01-01  00:00:06  Thursday        No   \n",
       "...          ...            ...         ...       ...       ...       ...   \n",
       "1048570  1048570  1423622182000  2015-02-10  21:36:22   Tuesday        No   \n",
       "1048571  1048571  1423622184000  2015-02-10  21:36:24   Tuesday        No   \n",
       "1048572  1048572  1423622185000  2015-02-10  21:36:25   Tuesday        No   \n",
       "1048573  1048573  1423622186000  2015-02-10  21:36:26   Tuesday        No   \n",
       "1048574  1048574  1423622189000  2015-02-10  21:36:29   Tuesday        No   \n",
       "\n",
       "         studyweek  studyday  egoid  egoconf  ...  alterconf  outgoing iphone  \\\n",
       "0              -33      -227  27169     0.95  ...        0.6        No      1   \n",
       "1              -33      -227  96184     0.95  ...        0.7        No      1   \n",
       "2              -33      -227  96184     0.95  ...        0.7        No      1   \n",
       "3              -33      -227  19538     0.95  ...        0.5        No      1   \n",
       "4              -33      -227  96184     0.95  ...        0.7        No      1   \n",
       "...            ...       ...    ...      ...  ...        ...       ...    ...   \n",
       "1048570        -27      -187  96689     0.95  ...        0.3       Yes      1   \n",
       "1048571        -27      -187  57697     0.95  ...        0.5        No      1   \n",
       "1048572        -27      -187  57697     0.95  ...        0.5        No      1   \n",
       "1048573        -27      -187  29232     0.95  ...        0.7       Yes      1   \n",
       "1048574        -27      -187  96689     0.95  ...        0.3       Yes      1   \n",
       "\n",
       "         eventtype eventtypedetail messagetype duration  length  bytes  \\\n",
       "0              SMS              iM         NaN      NaN    13.0    NaN   \n",
       "1         WhatsApp              DM           T      NaN     1.0    NaN   \n",
       "2         WhatsApp              DM           T      NaN     1.0    NaN   \n",
       "3              SMS              iM         NaN      NaN    12.0    NaN   \n",
       "4         WhatsApp              DM           T      NaN     2.0    NaN   \n",
       "...            ...             ...         ...      ...     ...    ...   \n",
       "1048570        SMS              iM         NaN      NaN     6.0    NaN   \n",
       "1048571        SMS              iM         NaN      NaN    26.0    NaN   \n",
       "1048572        SMS              iM         NaN      NaN     8.0    NaN   \n",
       "1048573        SMS              SM         NaN      NaN     9.0    NaN   \n",
       "1048574        SMS              iM         NaN      NaN    13.0    NaN   \n",
       "\n",
       "             _id  \n",
       "0              0  \n",
       "1              1  \n",
       "2              2  \n",
       "3              3  \n",
       "4              4  \n",
       "...          ...  \n",
       "1048570  1048570  \n",
       "1048571  1048571  \n",
       "1048572  1048572  \n",
       "1048573  1048573  \n",
       "1048574  1048574  \n",
       "\n",
       "[1048575 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "80MB-3Safuno"
   },
   "outputs": [],
   "source": [
    "def eventTypeMap(e_type):\n",
    "  return {\n",
    "        'Call': 0,\n",
    "        'MMS': 1,\n",
    "        'SMS': 2,\n",
    "        'WhatsApp': 3\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventTypeSynMap(e_type):\n",
    "  return {\n",
    "        'A': 0,\n",
    "        'B': 1,\n",
    "        'C': 2,\n",
    "        'D': 3,\n",
    "        'E': 4\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kmjkku1Ovi3o"
   },
   "outputs": [],
   "source": [
    "def indexEventTypeMap(index):\n",
    "  return {\n",
    "        0: 'Call',\n",
    "        1: 'MMS',\n",
    "        2: 'SMS',\n",
    "        3: 'WhatsApp'\n",
    "    }.get(index, 'Call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexEventTypeSynMap(e_type):\n",
    "  return {\n",
    "        0: 'A',\n",
    "        1: 'B',\n",
    "        2: 'C',\n",
    "        3: 'D',\n",
    "        4: 'E'\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FBMivgRYYc-I"
   },
   "outputs": [],
   "source": [
    "def getCuda():\n",
    "  gpu_avail = torch.cuda.is_available()\n",
    "  print(f\"Is the GPU available? {gpu_avail}\")\n",
    "\n",
    "  if(gpu_avail):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(\"Device\", device)\n",
    "\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "    cuda = torch.device('cuda')\n",
    "    return cuda\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vfE6Luk8ty6y"
   },
   "outputs": [],
   "source": [
    "def toTensor(events, events_ids, times, times_max, embedding_features, cuda):\n",
    "  timeScale = 1.0\n",
    "  if cuda:\n",
    "    t_events = torch.tensor(events, device=cuda).float()\n",
    "    t_events_ids = torch.tensor(events_ids, device=cuda).long()\n",
    "    t_times = torch.tensor(times/timeScale, device=cuda).float()\n",
    "    t_times_max = torch.tensor(times_max/timeScale, device=cuda).float()\n",
    "    t_embedding_features = torch.tensor(embedding_features, device=cuda).float()\n",
    "  else: \n",
    "    t_events = torch.tensor(events).float()\n",
    "    t_events_ids = torch.tensor(events_ids).long()\n",
    "    t_times = torch.tensor(times/timeScale).float()\n",
    "    t_times_max = torch.tensor(times_max/timeScale).float()\n",
    "    t_embedding_features = torch.tensor(embedding_features).float()\n",
    "\n",
    "  return t_events, t_events_ids, t_times, t_times_max, t_embedding_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7Msb0cCCXBhC"
   },
   "outputs": [],
   "source": [
    "def getPathDir():\n",
    "  return {\n",
    "        'NN': 'nn',\n",
    "        'GCN': 'gcn',\n",
    "        'TGCN': 'tgcn',\n",
    "        'W2V': 'w2v',\n",
    "        'TW2V': 'tw2v'\n",
    "    }.get(model, 'nn')\n",
    "\n",
    "database = 'syn' if useSyntheticData else 'nethealth'\n",
    "\n",
    "def getPath(e_type):\n",
    "  dir = getPathDir()\n",
    "  return './social-interactions/{}/{}_{}_{}_{}.pkl'.format(dir, e_type, seq_len, windows_p, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rVTueIhptTGa"
   },
   "outputs": [],
   "source": [
    "def readData():\n",
    "  with open(getPath('events'), 'rb') as fid:\n",
    "     events = pickle.load(fid)\n",
    "  with open(getPath('events_ids'), 'rb') as fid:\n",
    "     events_ids = pickle.load(fid)\n",
    "  with open(getPath('times'), 'rb') as fid:\n",
    "     times = pickle.load(fid)\n",
    "  with open(getPath('times_max'), 'rb') as fid:\n",
    "     times_max = pickle.load(fid)\n",
    "  with open(getPath('embedded'), 'rb') as fid:\n",
    "     all_embedded_events = pickle.load(fid)\n",
    "\n",
    "  return events, events_ids, times, times_max, all_embedded_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e-Pw1-x-tUYD"
   },
   "outputs": [],
   "source": [
    "def saveData(events, events_ids, times, times_max, all_embedded_events):\n",
    "  with open(getPath('events'), 'wb') as fid:\n",
    "     pickle.dump(events, fid)\n",
    "  with open(getPath('events_ids'), 'wb') as fid:\n",
    "     pickle.dump(events_ids, fid)\n",
    "  with open(getPath('times'), 'wb') as fid:\n",
    "     pickle.dump(times, fid)\n",
    "  with open(getPath('times_max'), 'wb') as fid:\n",
    "     pickle.dump(times_max, fid)\n",
    "  with open(getPath('embedded'), 'wb') as fid:\n",
    "     pickle.dump(all_embedded_events, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sYb00yz2s59J"
   },
   "outputs": [],
   "source": [
    "def encodeEvents(events):\n",
    "  num_of_seq, num_of_ev_per_seq = events.shape\n",
    "  events_one_hot = np.zeros((num_of_seq, num_of_ev_per_seq, n_types))\n",
    "  \n",
    "  for seq in range(num_of_seq):\n",
    "      for step in range(num_of_ev_per_seq):\n",
    "          ev = events[seq, step]\n",
    "          events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "  return events_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V6iod2lgQxKy"
   },
   "outputs": [],
   "source": [
    "def normalize(embedding):\n",
    "  if(np.min(embedding) == np.max(embedding)):\n",
    "    embedding_result = np.zeros_like(embedding).tolist()\n",
    "  else:\n",
    "    embedding_result = (embedding - np.min(embedding)) / (np.max(embedding) - np.min(embedding)).tolist()\n",
    "\n",
    "  return embedding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UiODCXHv15ui"
   },
   "outputs": [],
   "source": [
    "def dfToGraph(df, source, target, time, ev_type, create_using=nx.Graph()):\n",
    "    return nx.from_pandas_edgelist(df, source, target, edge_attr=[time, ev_type], create_using=create_using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rZ87XUbiSn-w"
   },
   "outputs": [],
   "source": [
    "def convertEgdeEventsDfToNodeEventsDf(df):\n",
    "  df_idx = df['_id']\n",
    "  df_idx_size = len(df_idx)\n",
    "  res = []\n",
    "  assignedIdx = []\n",
    "\n",
    "  for i, row in df.iterrows():\n",
    "    idx_1, source_node_1, target_node_1, type_1 =  row['_id'], row['source'], row['target'], row['type']\n",
    "\n",
    "    # node_sharing - dataframe przyszłych zdarzeń gdzie nadawca lub odbiorca są podmiotami tych zdarzeń \n",
    "    node_sharing = df[((df['source'].isin([source_node_1, target_node_1])) | (df['target'].isin([source_node_1, target_node_1]))) & (df['_id'] > idx_1)]\n",
    "    isAssigned = False\n",
    "\n",
    "    for j, other_row in node_sharing.iterrows():\n",
    "        idx_2, source_node_2, target_node_2, type_2 = other_row['_id'], other_row['source'], other_row['target'], other_row['type']\n",
    "        res.append([idx_1, idx_2, type_1, type_2])\n",
    "        assignedIdx.append(idx_2)\n",
    "        isAssigned = True\n",
    "\n",
    "    if(not isAssigned and not idx_1 in assignedIdx):\n",
    "        res.append([idx_1, idx_1, type_1, type_1])\n",
    "        \n",
    "  index_values = np.arange(len(res))\n",
    "    \n",
    "  # creating a list of column names\n",
    "  column_values = ['source_ev', 'target_ev', 'source_ev_type', 'target_ev_type']\n",
    "    \n",
    "  # creating the dataframe\n",
    "  df_res = pd.DataFrame(data = res, \n",
    "                    index = index_values, \n",
    "                    columns = column_values)\n",
    "  \n",
    "  col_source_ev = df_res['source_ev'].to_numpy()\n",
    "  col_target_ev = df_res['target_ev'].to_numpy()\n",
    "  nodes_idx = np.concatenate((col_source_ev, col_target_ev))\n",
    "\n",
    "  df_nodes = np.unique(nodes_idx)\n",
    "  df_nodes_size = len(df_nodes)\n",
    "\n",
    "  if(df_idx_size != df_nodes_size):\n",
    "    print('Not equal sizes: {} and {}'.format(df_idx_size, df_nodes_size))\n",
    "    for _, idx in enumerate(df_idx):\n",
    "      if(idx not in df_nodes):\n",
    "        print(idx)\n",
    "  \n",
    "  return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "onuezZVOBESV"
   },
   "outputs": [],
   "source": [
    "def dfToGraphWithEventsAsNode(df, source, target, create_using=nx.Graph()):\n",
    "    return nx.from_pandas_edgelist(df, source, target, create_using=create_using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "vp2WHf8S5qG4"
   },
   "outputs": [],
   "source": [
    "def drawGraph(graph):\n",
    "  if isinstance(graph, pd.DataFrame):\n",
    "    return display(graph)\n",
    "  nx.draw(graph, with_labels=True, font_weight='bold')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wVYe6w1a1egS"
   },
   "outputs": [],
   "source": [
    "#Build GCN\n",
    "def calcGCN(A,H,W):\n",
    "  I = np.identity(A.shape[0])\n",
    "  A_hat = A + I \n",
    "  D = np.diag(np.sum(A_hat, axis=0)) \n",
    "  D_half_norm = fractional_matrix_power(D, -0.5)\n",
    "  result = D_half_norm.dot(A_hat).dot(D_half_norm).dot(H).dot(W)\n",
    "    \n",
    "  #ReLU\n",
    "  return np.maximum(0,result)\n",
    "\n",
    "# Make one-hot encoded events with GCB embedding\n",
    "def getEncodedEventsGCN(temporal_graphs, seq_len, number_of_embedding_features):\n",
    "  embeddings = np.zeros((seq_len, number_of_embedding_features))\n",
    "  event_idx = 0\n",
    "\n",
    "  for idx, _graph in enumerate(temporal_graphs):\n",
    "    nodeEventsDf = convertEgdeEventsDfToNodeEventsDf(_graph)\n",
    "    graph = dfToGraphWithEventsAsNode(nodeEventsDf, 'source_ev', 'target_ev')\n",
    "    X = np.array(graph.nodes)\n",
    "    X = np.array(X).reshape(len(X),-1)\n",
    "\n",
    "    A = np.array(nx.adjacency_matrix(graph).todense()) \n",
    "\n",
    "    np.random.seed(77777)\n",
    "    gcn_hidden = 4 \n",
    "    n_y = gcn_out \n",
    "    W0 = np.random.randn(X.shape[1], gcn_hidden) * 0.01\n",
    "    W1 = np.random.randn(gcn_hidden, gcn_out) * 0.01\n",
    "\n",
    "    H1 = calcGCN(A, X, W0)\n",
    "    H2 = calcGCN(A, H1, W1)\n",
    "    \n",
    "    embedding = np.array(H2[:,0])\n",
    "    embedding = normalize(embedding)\n",
    "\n",
    "    if(len(embedding) != X.shape[0]):\n",
    "      print('Wrong embedding and X shapes')\n",
    "      print(len(embedding))\n",
    "      print(X.shape[0])\n",
    "\n",
    "    zip_embedding = zip(X.flatten().tolist(), embedding)\n",
    "    embedding_dictionary = dict(zip_embedding)\n",
    "    \n",
    "    if(len(X.flatten()) != len(_graph) or len(embedding) != len(_graph)):\n",
    "      print(len(X.flatten()))\n",
    "      print(len(embedding))\n",
    "      print(len(_graph))\n",
    "        \n",
    "    for i, event_row in _graph.iterrows():\n",
    "      embeddings[event_idx][0] = embedding_dictionary[event_row['_id']]\n",
    "      event_idx += 1\n",
    "\n",
    "  return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AiWk-Xl_s8Hz"
   },
   "outputs": [],
   "source": [
    "def generateData(df, seq_len, windows_p, number_of_embedding_features):\n",
    "  number_of_seqs = math.floor(df.shape[0] / seq_len)\n",
    "  events = np.zeros([number_of_seqs, seq_len], dtype=int)\n",
    "  embedded_events = []\n",
    "  times = np.zeros([number_of_seqs, seq_len+1], dtype=int)\n",
    "  times_max = np.zeros(number_of_seqs, dtype=int)\n",
    "\n",
    "  targets = []\n",
    "  sources = []\n",
    "  types = []\n",
    "  _ids = []\n",
    "\n",
    "  curr_seq = 0\n",
    "  curr_step = 0\n",
    "  first_seq_time = 0\n",
    "    \n",
    "  for index, row in tqdm(df.iterrows(), position=0, leave=True):\n",
    "    if(curr_seq >= number_of_seqs):\n",
    "      break\n",
    "\n",
    "    curr_step = index % seq_len\n",
    "    if curr_step == 0:\n",
    "       first_seq_time = row['epochtime']\n",
    "\n",
    "    event_type = eventTypeSynMap(row['eventtype']) if useSyntheticData else eventTypeMap(row['eventtype'])\n",
    "    events[curr_seq][curr_step] = event_type\n",
    "    times[curr_seq][curr_step] = (row['epochtime'] - first_seq_time) / 1000\n",
    "\n",
    "    targets.append(row['alterid'])\n",
    "    sources.append(row['egoid'])\n",
    "    types.append(event_type)\n",
    "    _ids.append(row['_id'])\n",
    "\n",
    "    if curr_step == seq_len - 1:\n",
    "      times_max[curr_seq] = np.max(times[curr_seq])\n",
    "      times[curr_seq][curr_step+1] = (df.iloc[[index + 1]]['epochtime'] - first_seq_time) / 1000\n",
    "\n",
    "      graph_times = times[curr_seq][:-1]\n",
    "      graphs_df = pd.DataFrame(data={'_id':_ids, 'time': graph_times, 'source':sources, 'target': targets, 'type': types})\n",
    "      min_time = min(graph_times)\n",
    "      max_time = max(graph_times)\n",
    "      window_duration = (max_time - min_time) / windows_p\n",
    "      temporal_graphs = []\n",
    "        \n",
    "      for window in range(windows_p):\n",
    "            begin = min_time + window_duration * window\n",
    "            end = min_time + window_duration * (window+1)\n",
    "            temporal_graphs.append(graphs_df.loc[(graphs_df['time'] >= begin) & (graphs_df['time'] < end)])\n",
    "\n",
    "      encoded_events = getEncodedEventsGCN(temporal_graphs, seq_len, number_of_embedding_features)\n",
    "      embedded_events.append(encoded_events)\n",
    "\n",
    "      targets = []\n",
    "      sources = []\n",
    "      types = []\n",
    "      _ids = []\n",
    "      \n",
    "      curr_seq += 1\n",
    "\n",
    "  return events, times, times_max, np.array(embedded_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hWY0Yv7ttQdL",
    "outputId": "c592e858-042e-4813-fc8b-dbdf334cc68c"
   },
   "outputs": [],
   "source": [
    "if(use_data_from_files):\n",
    "  all_events, all_events_ids, all_times, all_times_max, all_embedded_events = readData()\n",
    "else:\n",
    "  prep_time_start = timeit.default_timer()\n",
    "  all_events_ids, all_times, all_times_max, all_embedded_events = generateData(events_df, seq_len, windows_p, number_of_embedding_features)\n",
    "  all_events = encodeEvents(all_events_ids)\n",
    "  prep_time_stop = timeit.default_timer()\n",
    "  prep_time = prep_time_stop - prep_time_start\n",
    "  \n",
    "  saveData(all_events, all_events_ids, all_times, all_times_max, all_embedded_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1398, 750, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embedded_events.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41333643, 0.41333643, 0.28004957, ..., 0.89693878, 1.        ,\n",
       "       0.89693878])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embedded_events[all_embedded_events!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_features = []\n",
    "for seq in all_embedded_events:\n",
    "  event_features = []\n",
    "  for event in seq:\n",
    "    if model == 'W2V' or model == 'TW2V':\n",
    "      features =[event[0],event[1]] * int( number_of_spatio_features /2)\n",
    "    else:\n",
    "      features = [event[0]] * number_of_spatio_features\n",
    "    event_features.append(features)\n",
    "  seq_features.append(event_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1398, 750, 1)\n",
      "[0.41333643]\n",
      "[0.41333643]\n"
     ]
    }
   ],
   "source": [
    "seq_features = np.array(seq_features)\n",
    "print(seq_features.shape)\n",
    "print(seq_features[0][1])\n",
    "print(all_embedded_events[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedded_events = seq_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "aZucKFgmtitr"
   },
   "outputs": [],
   "source": [
    "test_train_split = 0.8\n",
    "num_of_seqs = all_events.shape[0]\n",
    "num_of_train_seqs = math.ceil(num_of_seqs * test_train_split)\n",
    "split_details = [num_of_train_seqs]\n",
    "\n",
    "train_events, test_events = np.split(all_events, split_details)\n",
    "train_events_ids, test_events_ids = np.split(all_events_ids, split_details)\n",
    "train_times, test_times = np.split(all_times, split_details)\n",
    "train_times_max, test_times_max = np.split(all_times_max, split_details)\n",
    "train_embedding_features, test_embedding_features = np.split(all_embedded_events, split_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xc5hcGcetnz5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1398, 750, 4)\n",
      "(1398, 750)\n",
      "(1398, 751)\n",
      "(1398,)\n",
      "(1398, 750, 1)\n"
     ]
    }
   ],
   "source": [
    "print(all_events.shape)\n",
    "print(all_events_ids.shape)\n",
    "print(all_times.shape)\n",
    "print(all_times_max.shape)\n",
    "print(all_embedded_events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yFTOWYLYZcwL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n",
      "Device cuda\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "cuda = getCuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "QUcFWo9et5kh"
   },
   "outputs": [],
   "source": [
    "t_events, t_events_ids, t_times, t_times_max, t_embedded_events = toTensor(train_events, train_events_ids, train_times, train_times_max, train_embedding_features, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fL702Ydff9Xw"
   },
   "outputs": [],
   "source": [
    "class GCNNNLSTM(nn.Module):\n",
    "  # input matrix size:  (batch_size, sequence_length, event_features_length)\n",
    "  # weight matrix size:  (event_features_length, output_size)\n",
    "  # output_size = hidden_size\n",
    "  # output_size:  (batch_size, output_size) for each of element on the sequence\n",
    "  # output_size:  (batch_size, sequence_length, output_size) for all elements on the sequence\n",
    "  # weight_matrix: (output_size, output_size) \n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, number_of_spatio_features: int, transform_fun, sigma = torch.sigmoid):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.number_of_spatio_features = number_of_spatio_features\n",
    "\n",
    "        self.W = nn.Linear(self.input_size, 7*self.hidden_size)\n",
    "        # 1 - input gate \n",
    "        # 2 - forget gate\n",
    "        # 3 - z gate\n",
    "        # 4 - output gate\n",
    "        # 5 - i_dash gate\n",
    "        # 6 - f_dash gate\n",
    "        # 7 - delta gate\n",
    "        self.U = nn.Linear(self.hidden_size, 7*self.hidden_size)\n",
    "        # embedding features\n",
    "        self.E = nn.Linear(self.number_of_spatio_features, 7*self.hidden_size)\n",
    "        # output mapping from hidden vectors to unnormalized intensity\n",
    "        self.L = nn.Linear(self.hidden_size, self.input_size, bias=False)\n",
    "        \n",
    "        self.initWeights()\n",
    "        self.sigma = sigma\n",
    "        self.transform_fun = transform_fun\n",
    "        self.scale = nn.Parameter(torch.ones(self.input_size, requires_grad=True))\n",
    "\n",
    "    def initWeights(self):\n",
    "        nn.init.normal_(self.W.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.W.bias, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.E.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.E.bias, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.U.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.U.bias, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.L.weight, mean=0.0, std=0.01)\n",
    "\n",
    "    def calcLambdaK(self, h_t): \n",
    "      if(self.transform_fun == 'RELU'):\n",
    "        return torch.relu(h_t)\n",
    "      if self.transform_fun == 'SOFTPLUS':\n",
    "        return torch.log(1 + torch.exp(self.L(h_t)))\n",
    "      if self.transform_fun == 'SOFTPLUS_SCALE':\n",
    "        return self.scale * torch.log(1 + torch.exp(self.L(h_t)/self.scale))\n",
    "      raise Exception('Unsupported transform_fun')\n",
    "\n",
    "    def forward(self, events, times, embedded_events):\n",
    "        batch_size, batch_length, _ = events.shape\n",
    "\n",
    "        delta_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        o_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        c_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        c_dash_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "\n",
    "        lambda_seq = torch.zeros((batch_size, batch_length, self.input_size), device=cuda)\n",
    "\n",
    "        h_t = torch.zeros((batch_size, self.hidden_size), device=cuda).float()\n",
    "        c_t = torch.zeros((batch_size, self.hidden_size), device=cuda).float()\n",
    "        c_dash = torch.zeros((batch_size, self.hidden_size), device=cuda).float()\n",
    "\n",
    "        for event_idx in range(batch_length):\n",
    "          x = events[:, event_idx, :]\n",
    "          x_embed = embedded_events[:, event_idx, :]\n",
    "\n",
    "          outs = self.W(x) + self.U(h_t) + self.E(x_embed)\n",
    "\n",
    "          # 1 - input gate \n",
    "          # 2 - forget gate\n",
    "          # 3 - z gate\n",
    "          # 4 - output gate\n",
    "          # 5 - i_dash gate\n",
    "          # 6 - f_dash gate\n",
    "          # 7 - delta gate\n",
    "          i, f, z, o, i_dash, f_dash, delta = (\n",
    "                self.sigma(outs[:, :self.hidden_size]),\n",
    "                self.sigma(outs[:, self.hidden_size:self.hidden_size*2]), \n",
    "                2 * self.sigma(outs[:, self.hidden_size*2:self.hidden_size*3]) - 1, \n",
    "                self.sigma(outs[:, self.hidden_size*3:self.hidden_size*4]),\n",
    "                self.sigma(outs[:, self.hidden_size*4:self.hidden_size*5]), \n",
    "                self.sigma(outs[:, self.hidden_size*5:self.hidden_size*6]), \n",
    "                F.softplus(outs[:, self.hidden_size*6:self.hidden_size*7]), \n",
    "          )\n",
    "\n",
    "          c = f * c_t + i * z\n",
    "          c_dash = f_dash * c_dash + i_dash * z\n",
    "          t_now = times[:, event_idx].view(-1, 1)\n",
    "          t_next = times[:, event_idx + 1].view(-1, 1) \n",
    "          c_t = c_dash + (c - c_dash) * torch.exp(-delta * (t_next - t_now))\n",
    "          h_t = o * (2 * self.sigma(2 * c_t) - 1)\n",
    "          lambda_k = self.calcLambdaK(h_t)\n",
    "\n",
    "          c_seq[:, event_idx, :] = c\n",
    "          c_dash_seq[:, event_idx, :] = c_dash\n",
    "          o_seq[:, event_idx, :] = o\n",
    "          delta_seq[:, event_idx, :] = delta\n",
    "          lambda_seq[:, event_idx, :] = lambda_k\n",
    "\n",
    "        return c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq\n",
    "\n",
    "    def getLoss(self, events_ids, times, max_times, c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq):\n",
    "\n",
    "        batch_size, batch_length = events_ids.shape\n",
    "\n",
    "        original_loss = 0.\n",
    "\n",
    "        for ev in range(batch_length):\n",
    "            lambdas = lambda_seq[torch.arange(batch_size), ev, events_ids[:, ev]]\n",
    "            log_lambdas = torch.log(lambdas)\n",
    "            \n",
    "            original_loss -= torch.sum(log_lambdas)\n",
    "\n",
    "        simulated_loss = 0.\n",
    "        trends = torch.rand((batch_size, batch_length), device=cuda) * max_times.view(-1, 1) # (1 x batch_size) to (batch_size x 1) to enable multiply\n",
    "        t_up = torch.searchsorted(times, trends)\n",
    "        I = torch.zeros((batch_size), device=cuda)\n",
    "        \n",
    "        for t_idx in range(batch_length):\n",
    "            T = trends[:, t_idx].view(-1,1)\n",
    "\n",
    "            idx = t_up[:, t_idx]\n",
    "            if torch.any(idx < 1):\n",
    "                continue\n",
    "            \n",
    "            t = times.gather(1, (idx-1).view(-1, 1))\n",
    "            \n",
    "            c_seq_x_dim = c_seq.shape[0]\n",
    "            c = c_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            c_dash = c_dash_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            delta = delta_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            o = o_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            c_t = c_dash + (c - c_dash)*torch.exp(-delta * (T - t))\n",
    "            h_t = o * (2 * self.sigma(2 * c_t) - 1)\n",
    "            lambda_k = self.calcLambdaK(h_t)\n",
    "            lambda_total = torch.sum(lambda_k, dim=1)\n",
    "            I += lambda_total * max_times / batch_length\n",
    "        \n",
    "\n",
    "        simulated_loss = torch.sum(I, dim=0)\n",
    "        loss = original_loss + simulated_loss\n",
    "\n",
    "        return loss / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = getPathDir()\n",
    "\n",
    "reload = False \n",
    "if reload: \n",
    "    last_epoch = 15\n",
    "    try:\n",
    "        net = torch.load(\"./social-interactions/{}/model_{}_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, windows_p, last_epoch))\n",
    "    except:\n",
    "        print(\"No saved network found. Starting from scratch\")\n",
    "        net = GCNNNLSTM(n_types, hidden_size, number_of_spatio_features, transform_fun)\n",
    "else: \n",
    "    net = GCNNNLSTM(n_types, hidden_size, number_of_spatio_features, transform_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "FrT0rhxGT8Tq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNNNLSTM(\n",
       "  (W): Linear(in_features=4, out_features=448, bias=True)\n",
       "  (U): Linear(in_features=64, out_features=448, bias=True)\n",
       "  (E): Linear(in_features=1, out_features=448, bias=True)\n",
       "  (L): Linear(in_features=64, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "X5zK4c_NomvX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [12:59<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3594.031900678362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "losses = []\n",
    "train_time_start = timeit.default_timer()\n",
    "previous_net = None\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    print(\"\\nEpoch:{}\".format(epoch+1), flush=True)\n",
    "\n",
    "    batch_loss = []  \n",
    "    if(epoch > 0):\n",
    "        previous_net = net\n",
    "\n",
    "    perm = torch.randperm(t_events.shape[0])\n",
    "    for batch_index in tqdm(range(0, t_events.shape[0], batch_size), position=0, leave=True):\n",
    "        batch_begin = batch_index\n",
    "        batch_end = batch_index + batch_size\n",
    "\n",
    "        batch_events = t_events[perm][batch_begin:batch_end]\n",
    "        batch_events_ids = t_events_ids[perm][batch_begin:batch_end]\n",
    "        batch_times = t_times[perm][batch_begin:batch_end]\n",
    "        batch_max_times = t_times_max[perm][batch_begin:batch_end]\n",
    "        batch_embedded_events = t_embedded_events[perm][batch_begin:batch_end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq = net.forward(batch_events, batch_times, batch_embedded_events)\n",
    "\n",
    "        loss = net.getLoss(batch_events_ids, batch_times, batch_max_times, c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq)\n",
    "        batch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_batch_loss = mean(batch_loss)\n",
    "    print(mean_batch_loss)\n",
    "    if(math.isnan(mean_batch_loss) or not math.isfinite(mean_batch_loss)):\n",
    "      net = previous_net\n",
    "      break\n",
    "    losses.append(mean_batch_loss)\n",
    "    torch.save(net, \"./social-interactions/{}/model_{}_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, windows_p, epoch+1))\n",
    "\n",
    "train_time_stop = timeit.default_timer()\n",
    "train_time = train_time_stop - train_time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "IjscZY0V1OSG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Długość sekwencji: 750\n",
      "Liczba rodzajów interakcji: 4\n",
      "Liczba epok: 1\n",
      "Rozmair porcji (batch): 10\n",
      "Liczba ukrytych neuronów sieci: 64\n",
      "Czas trenowania: 779.8584637\n",
      "Liczba podziałów temporalnych: 3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prep_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCzas trenowania: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_time))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba podziałów temporalnych: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(windows_p))\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCzas przygotowania sekwencji: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mprep_time\u001b[49m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSztuczny zbiór danych: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(useSyntheticData))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiczba cech przestrzennych: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(useSyntheticData))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prep_time' is not defined"
     ]
    }
   ],
   "source": [
    "print('Długość sekwencji: {}'.format(seq_len))\n",
    "print('Liczba rodzajów interakcji: {}'.format(n_types))\n",
    "print('Liczba epok: {}'.format(n_epoch))\n",
    "print('Rozmair porcji (batch): {}'.format(batch_size))\n",
    "print('Liczba ukrytych neuronów sieci: {}'.format(hidden_size))\n",
    "print('Czas trenowania: {}'.format(train_time))\n",
    "print('Liczba podziałów temporalnych: {}'.format(windows_p))\n",
    "print('Czas przygotowania sekwencji: {}'.format(prep_time))\n",
    "print('Sztuczny zbiór danych: {}'.format(useSyntheticData))\n",
    "print('Liczba cech przestrzennych: {}'.format(useSyntheticData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsIyYZ2zDF9f"
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01yxTlscsYAu"
   },
   "outputs": [],
   "source": [
    "def singleSeqThinningAlgorithm(net, seq_events, seq_events_ids, seq_times, embedded_events):\n",
    "  n_events, n_types = seq_events.shape\n",
    "  c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq = net.forward(seq_events.view(-1, n_events, n_types), seq_times.view(-1, n_events+1), embedded_events.view(-1, n_events, number_of_spatio_features))\n",
    "\n",
    "  events_predicted = torch.zeros(n_events)\n",
    "  times_predicted = torch.zeros(n_events)\n",
    "  correct_pred = torch.zeros(n_events)\n",
    "\n",
    "  for i in range(n_events):\n",
    "    c = c_seq[:, i]\n",
    "    c_dash = c_dash_seq[:, i]\n",
    "    o = o_seq[:, i]\n",
    "    delta = delta_seq[:, i]\n",
    "    t = seq_times[i].item()\n",
    "\n",
    "    c_max = torch.max(c, c_dash)\n",
    "    h_max = o * (2 * net.sigma(2 * c_max) - 1)\n",
    "    lambda_max = net.scale * torch.log(1 + torch.exp(net.L(h_max)/net.scale)).view(n_types)\n",
    "    lambda_max_total = torch.sum(lambda_max).item()\n",
    "\n",
    "    temp_t = t\n",
    "    lambda_total = math.inf\n",
    "\n",
    "    stop = False\n",
    "    stop_arr = []\n",
    "    while (not stop):    \n",
    "      delta_time = random.expovariate(lambda_max_total)\n",
    "      temp_t += delta_time\n",
    "\n",
    "      c_t = c_dash + (c - c_dash) * torch.exp(-delta * (temp_t - t))\n",
    "      h_t = o * (2 * net.sigma(2 * c_t) - 1)\n",
    "      lambda_k = net.scale * torch.log(1 + torch.exp(net.L(h_t)/net.scale)).view(n_types)\n",
    "\n",
    "      u = np.random.rand()\n",
    "      stop_arr = (u * lambda_max > lambda_k).nonzero().squeeze(1)\n",
    "      stop = len(stop_arr) > 0\n",
    "\n",
    "    for _, ev in enumerate(torch.argsort(lambda_k, descending=True)):\n",
    "      ev = ev.item()\n",
    "      if(ev in stop_arr):\n",
    "        times_predicted[i] = temp_t\n",
    "        events_predicted[i] = ev\n",
    "        if ev == seq_events_ids[i].item():\n",
    "          correct_pred[i] = 1\n",
    "        break;\n",
    "\n",
    "  return times_predicted, events_predicted, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIYC7PqRtKhP"
   },
   "outputs": [],
   "source": [
    "def getDetails(t_events, t_events_ids, t_times, seq_idx, seq_len, t_embedded_events_test):\n",
    "  return t_events[seq_idx, :seq_len], t_events_ids[seq_idx, :seq_len], t_times[seq_idx, :seq_len+1], t_embedded_events_test[seq_idx, :seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "797xxyCEqEzy"
   },
   "outputs": [],
   "source": [
    "def getAccByType(pred_events, true_events):\n",
    "  number_of_types = np.zeros(n_types)\n",
    "  number_of_true_pred_types = np.zeros(n_types)\n",
    "\n",
    "  for index, true_event in enumerate(true_events):\n",
    "    number_of_types[true_event] += 1\n",
    "    \n",
    "    if(true_event == pred_events[index]):\n",
    "      number_of_true_pred_types[true_event] += 1\n",
    "\n",
    "  for index, number_of_type in enumerate(number_of_types):\n",
    "    if(number_of_type == 0):\n",
    "      number_of_true_pred_types[index] = 1\n",
    "      number_of_types[index] = -1\n",
    "\n",
    "  acc_by_type = number_of_true_pred_types / number_of_types\n",
    "\n",
    "  return number_of_true_pred_types, number_of_types, acc_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVTzZMbSulGh"
   },
   "outputs": [],
   "source": [
    "def plotAccByType(acc_by_type):\n",
    "  seq_size = acc_by_type.shape[0]\n",
    "\n",
    "  acc_by_type = np.where(acc_by_type == -1, np.nan, acc_by_type)\n",
    "\n",
    "  plt.figure(figsize=(100,5))\n",
    "  plt.subplot(1,2,1)\n",
    "  for _type in range(n_types):\n",
    "      plt.plot(np.arange(0, seq_size, 1), acc_by_type[:,_type],'o', label=indexEventTypeSynMap(_type) if useSyntheticData else indexEventTypeMap(_type))\n",
    "\n",
    "  plt.legend(fontsize=14)\n",
    "  plt.ylabel(\"Dokładność predykcji\", fontsize=16)\n",
    "  plt.xlabel(\"Sekwencje\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsoyzEXrs9Gi"
   },
   "outputs": [],
   "source": [
    "n_test = test_events.shape[0]\n",
    "n_seq_max = test_events.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxWspl8SZeX3"
   },
   "outputs": [],
   "source": [
    "cuda = getCuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Y65NVWCs-0n"
   },
   "outputs": [],
   "source": [
    "t_events_test, t_events_ids_test, t_times_test, t_times_max_test, t_embedded_events_test = toTensor(test_events, test_events_ids, test_times, test_times_max, test_embedding_features, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmkzhWaVqfmp"
   },
   "outputs": [],
   "source": [
    "def calcAccForAllSequences():\n",
    "    all_pred_times = torch.ones(n_test, n_seq_max) * -1 \n",
    "    acc_by_type = np.zeros((n_test,  n_types)) * -1\n",
    "    acc_arr = torch.zeros(n_test)\n",
    "\n",
    "    for idx in tqdm(range(n_test), position=0, leave=True):\n",
    "        seq_len = len(test_events[idx])\n",
    "        seq_events, seq_labels, times, embedded_events = getDetails(t_events, t_events_ids, t_times, idx, seq_len, t_embedded_events_test)\n",
    "        times_predicted, events_predicted, correct_pred  = singleSeqThinningAlgorithm(net, seq_events, seq_labels, times, embedded_events)\n",
    "        number_of_true_pred_types, number_of_types, acc_values_by_type = getAccByType(events_predicted, seq_labels)\n",
    "        acc_by_type[idx] = acc_values_by_type\n",
    "        acc_arr[idx] = torch.sum(correct_pred)/len(correct_pred)\n",
    "        all_pred_times[idx, :seq_len] = times_predicted\n",
    "    \n",
    "calcAccForAllSequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qQn17yWw45x"
   },
   "outputs": [],
   "source": [
    "plotAccByType(acc_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUjisu0GqhZ6"
   },
   "outputs": [],
   "source": [
    "acc_arr = acc_arr.numpy()\n",
    "all_pred_times = all_pred_times.numpy()\n",
    "events_predicted = events_predicted.numpy()\n",
    "\n",
    "print(\"Średnia dokładność predykcji przyszłych rodzajów zdarzeń: {:.4f}%\".format(np.mean(acc_arr)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMxMjOAwqiC0"
   },
   "outputs": [],
   "source": [
    "seq_avgs = np.zeros(n_test)\n",
    "seq_log_avgs = np.zeros(n_test)\n",
    "\n",
    "for seq in range(n_test):\n",
    "    seq_len = len(test_events[seq])\n",
    "    actual_time = test_times[seq, 1:seq_len]\n",
    "    actual_time = [i if i != 0 else 1 for i in actual_time]\n",
    "    predicted_time = all_pred_times[seq, 1:seq_len]\n",
    "    dT2 = (predicted_time - actual_time)**2\n",
    "    dT2_avg = np.sum(dT2)/seq_len\n",
    "    seq_avgs[seq] = dT2_avg\n",
    "    \n",
    "print(\"Pierwiastek z uśrednionego błędu średniokwadratowego wartości czasu dla {} sekwencji testowych: {}\".format(n_test, np.sqrt(np.mean(seq_avgs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccForAllEpoches():\n",
    "    for epoch in range(n_epoch):\n",
    "        try:\n",
    "            net = torch.load(\"gdrive/My Drive/social-interactions/{}/model_{}_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, windows_p, epoch+1))\n",
    "\n",
    "        except:\n",
    "            print(\"No saved network found. Starting from scratch\")\n",
    "            net = NNLSTM(n_types, hidden_size, transform_fun)\n",
    "\n",
    "        net.to(cuda)\n",
    "\n",
    "        all_pred_times = torch.ones(n_test, n_seq_max)*-1  # negative time means no event occurred\n",
    "        acc_by_type = np.zeros((n_test,  n_types)) * -1\n",
    "        acc_arr = torch.zeros(n_test)\n",
    "\n",
    "        for idx in tqdm(range(n_test), position=0, leave=True):\n",
    "          seq_len = len(test_events[idx])\n",
    "          seq_events, seq_labels, times = getDetails(t_events, t_events_ids, t_times, idx, seq_len)\n",
    "          times_predicted, events_predicted, correct_pred  = singleSeqThinningAlgorithm(net, seq_events, seq_labels, times)\n",
    "          number_of_true_pred_types, number_of_types, acc_values_by_type = getAccByType(events_predicted, seq_labels)\n",
    "\n",
    "          acc_by_type[idx] = acc_values_by_type\n",
    "          acc_arr[idx] = torch.sum(correct_pred)/len(correct_pred)\n",
    "          all_pred_times[idx, :seq_len] = times_predicted\n",
    "        acc_arr = acc_arr.numpy()\n",
    "        all_pred_times = all_pred_times.numpy()\n",
    "        events_predicted = events_predicted.numpy()\n",
    "\n",
    "        print(\"Średnia dokładność predykcji przyszłych rodzajów zdarzeń dla {}: {:.4f}%\".format(epoch+1, np.mean(acc_arr)*100))\n",
    "        \n",
    "calcAccForAllEpoches()        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN graph nethealth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
