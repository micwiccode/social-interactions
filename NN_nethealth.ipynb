{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB9-iQ4jfjgI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from statistics import mean\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IXnlrVxpkEb"
   },
   "outputs": [],
   "source": [
    "useSyntheticData = False\n",
    "\n",
    "# syn=5 nethealt=4\n",
    "n_types = 4\n",
    "n_epoch = 15\n",
    "seq_len = 750\n",
    "batch_size = 10\n",
    "hidden_size = 64\n",
    "# RELU | SOFTPLUS | SOFTPLUS_SCALE\n",
    "transform_fun = 'SOFTPLUS_SCALE'\n",
    "\n",
    "use_data_from_files = True \n",
    "\n",
    "# NN | GCN | TGCN | W2V | TW2V\n",
    "model = 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "MFuEwU0Eflaz",
    "outputId": "ed9154e6-3c95-4266-cc04-5dd349292634"
   },
   "outputs": [],
   "source": [
    "if(useSyntheticData):\n",
    "  events_df = pd.read_csv('./social-interactions/events_syn.csv')\n",
    "else:\n",
    "  events_df = pd.read_csv('./social-interactions/events.csv')  \n",
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYXlXRlzfrhO"
   },
   "outputs": [],
   "source": [
    "events_df = events_df.sort_values(by=['epochtime'], ascending=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZfP67HoOPJ7T"
   },
   "outputs": [],
   "source": [
    "if('_id' not in events_df.columns):\n",
    "  events_df['_id'] = events_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80MB-3Safuno"
   },
   "outputs": [],
   "source": [
    "def eventTypeMap(e_type):\n",
    "  return {\n",
    "        'Call': 0,\n",
    "        'MMS': 1,\n",
    "        'SMS': 2,\n",
    "        'WhatsApp': 3\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventTypeSynMap(e_type):\n",
    "  return {\n",
    "        'A': 0,\n",
    "        'B': 1,\n",
    "        'C': 2,\n",
    "        'D': 3,\n",
    "        'E': 4\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmjkku1Ovi3o"
   },
   "outputs": [],
   "source": [
    "def indexEventTypeMap(index):\n",
    "  return {\n",
    "        0: 'Call',\n",
    "        1: 'MMS',\n",
    "        2: 'SMS',\n",
    "        3: 'WhatsApp'\n",
    "    }.get(index, 'Call')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexEventTypeSynMap(e_type):\n",
    "  return {\n",
    "        0: 'A',\n",
    "        1: 'B',\n",
    "        2: 'C',\n",
    "        3: 'D',\n",
    "        4: 'E'\n",
    "    }.get(e_type, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulnP991NoLKL"
   },
   "outputs": [],
   "source": [
    "def getCuda():\n",
    "  gpu_avail = torch.cuda.is_available()\n",
    "  print(f\"Is the GPU available? {gpu_avail}\")\n",
    "\n",
    "\n",
    "  if(gpu_avail):\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(\"Device\", device)\n",
    "\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    cuda = torch.device('cuda')\n",
    "    return cuda\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfE6Luk8ty6y"
   },
   "outputs": [],
   "source": [
    "def toTensor(events, events_ids, times, times_max, cuda=None):\n",
    "  timeScale = 1.0\n",
    "  if cuda:\n",
    "      t_events = torch.tensor(events, device=cuda).float()\n",
    "      t_events_ids = torch.tensor(events_ids, device=cuda).long()\n",
    "      t_times = torch.tensor(times/timeScale, device=cuda).float()\n",
    "      t_times_max = torch.tensor(times_max/timeScale, device=cuda).float()\n",
    "  else: \n",
    "      t_events = torch.tensor(events).float()\n",
    "      t_events_ids = torch.tensor(events_ids).long()\n",
    "      t_times = torch.tensor(times/timeScale).float()\n",
    "      t_times_max = torch.tensor(times_max/timeScale).float()\n",
    "\n",
    "  return t_events, t_events_ids, t_times, t_times_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJbJqWVcpLih"
   },
   "outputs": [],
   "source": [
    "def getPathDir():\n",
    "  return {\n",
    "        'NN': 'nn',\n",
    "        'GCN': 'gcn',\n",
    "        'TGCN': 'tgcn',\n",
    "        'W2V': 'w2v',\n",
    "        'TW2V': 'tw2v'\n",
    "    }.get(model, 'nn')\n",
    "\n",
    "database = 'syn' if useSyntheticData else 'nethealth'\n",
    "\n",
    "def getPath(e_type):\n",
    "  dir = getPathDir()\n",
    "  return './social-interactions/{}/{}_{}_{}.pkl'.format(dir, e_type, seq_len, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVTueIhptTGa"
   },
   "outputs": [],
   "source": [
    "def readData():\n",
    "  with open(getPath('events'), 'rb') as fid:\n",
    "     events = pickle.load(fid)\n",
    "  with open(getPath('events_ids'), 'rb') as fid:\n",
    "     events_ids = pickle.load(fid)\n",
    "  with open(getPath('times'), 'rb') as fid:\n",
    "     times = pickle.load(fid)\n",
    "  with open(getPath('times_max'), 'rb') as fid:\n",
    "     times_max = pickle.load(fid)\n",
    "\n",
    "  return events, events_ids, times, times_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-Pw1-x-tUYD"
   },
   "outputs": [],
   "source": [
    "def saveData(events, events_ids, times, times_max):\n",
    "  with open(getPath('events'), 'wb') as fid:\n",
    "     pickle.dump(events, fid)\n",
    "  with open(getPath('events_ids'), 'wb') as fid:\n",
    "     pickle.dump(events_ids, fid)\n",
    "  with open(getPath('times'), 'wb') as fid:\n",
    "     pickle.dump(times, fid)\n",
    "  with open(getPath('times_max'), 'wb') as fid:\n",
    "     pickle.dump(times_max, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYb00yz2s59J"
   },
   "outputs": [],
   "source": [
    "def encodeEvents(events):\n",
    "  num_of_seq, num_of_ev_per_seq = events.shape\n",
    "  events_one_hot = np.zeros((num_of_seq, num_of_ev_per_seq, n_types))\n",
    "  \n",
    "  for seq in range(num_of_seq):\n",
    "      for step in range(num_of_ev_per_seq):\n",
    "          ev = events[seq, step]\n",
    "          events_one_hot[seq, step, ev] = 1.0\n",
    "\n",
    "  return events_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiWk-Xl_s8Hz"
   },
   "outputs": [],
   "source": [
    "def generateData(df, seq_len):\n",
    "  display(df)\n",
    "  number_of_seqs = math.floor(df.shape[0] / seq_len)\n",
    "  events = np.zeros([number_of_seqs, seq_len], dtype=int)\n",
    "  times = np.zeros([number_of_seqs, seq_len+1], dtype=int)\n",
    "  times_max = np.zeros(number_of_seqs, dtype=int)\n",
    "\n",
    "  curr_seq = 0\n",
    "  curr_step = 0\n",
    "  first_seq_time = 0\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "    if(curr_seq >= number_of_seqs):\n",
    "      break\n",
    "\n",
    "    curr_step = index % seq_len\n",
    "    if curr_step == 0:\n",
    "       first_seq_time = row['epochtime']\n",
    "\n",
    "    events[curr_seq][curr_step] = eventTypeSynMap(row['eventtype']) if useSyntheticData else eventTypeMap(row['eventtype'])\n",
    "    times[curr_seq][curr_step] = (row['epochtime'] - first_seq_time) / 1000\n",
    "\n",
    "    if curr_step == seq_len - 1:\n",
    "      times_max[curr_seq] = np.max(times[curr_seq])\n",
    "      times[curr_seq][curr_step+1] = (df.iloc[[index + 1]]['epochtime'] - first_seq_time) / 1000\n",
    "      curr_seq += 1\n",
    "\n",
    "  return events, times, times_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWY0Yv7ttQdL"
   },
   "outputs": [],
   "source": [
    "if(use_data_from_files):\n",
    "  all_events, all_events_ids, all_times, all_times_max = readData()\n",
    "else:\n",
    "  prep_time_start = timeit.default_timer()\n",
    "\n",
    "  all_events_ids, all_times, all_times_max = generateData(events_df, seq_len)\n",
    "  all_events = encodeEvents(all_events_ids)\n",
    "  prep_time_stop = timeit.default_timer()\n",
    "  prep_time = prep_time_stop - prep_time_start\n",
    "\n",
    "  saveData(all_events, all_events_ids, all_times, all_times_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZucKFgmtitr"
   },
   "outputs": [],
   "source": [
    "test_train_split = 0.8\n",
    "num_of_seqs = all_events.shape[0]\n",
    "num_of_train_seqs = math.ceil(num_of_seqs * test_train_split)\n",
    "split_details = [num_of_train_seqs]\n",
    "\n",
    "train_events, test_events = np.split(all_events, split_details)\n",
    "train_events_ids, test_events_ids = np.split(all_events_ids, split_details)\n",
    "train_times, test_times = np.split(all_times, split_details)\n",
    "train_times_max, test_times_max = np.split(all_times_max, split_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc5hcGcetnz5",
    "outputId": "39c1c20c-9c3d-43ae-90b6-5936ba4cecc0"
   },
   "outputs": [],
   "source": [
    "print(all_events.shape)\n",
    "print(all_events_ids.shape)\n",
    "print(all_times.shape)\n",
    "print(all_times_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-Z9poeEqLWr",
    "outputId": "2d6f0dc3-1a40-43fa-df25-564888c09a81"
   },
   "outputs": [],
   "source": [
    "cuda = getCuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUcFWo9et5kh"
   },
   "outputs": [],
   "source": [
    "t_events, t_events_ids, t_times, t_times_max = toTensor(train_events, train_events_ids, train_times, train_times_max, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fL702Ydff9Xw"
   },
   "outputs": [],
   "source": [
    "class NNLSTM(nn.Module):\n",
    "  # input matrix size:  (batch_size, sequence_length, event_features_length)\n",
    "  # weight matrix size:  (event_features_length, output_size)\n",
    "  # output_size = hidden_size\n",
    "  # output_size:  (batch_size, output_size) for each of element on the sequence\n",
    "  # output_size:  (batch_size, sequence_length, output_size) for all elements on the sequence\n",
    "  # weight_matrix: (output_size, output_size) \n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, transform_fun, sigma = torch.sigmoid):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.transform_fun = transform_fun\n",
    "\n",
    "        self.W = nn.Linear(self.input_size, 7*self.hidden_size)\n",
    "        # 1 - input gate \n",
    "        # 2 - forget gate\n",
    "        # 3 - z gate\n",
    "        # 4 - output gate\n",
    "        # 5 - i_dash gate\n",
    "        # 6 - f_dash gate\n",
    "        # 7 - delta gate\n",
    "        self.U = nn.Linear(self.hidden_size, 7*self.hidden_size)\n",
    "        # output mapping from hidden vectors to unnormalized intensity\n",
    "        self.L = nn.Linear(self.hidden_size, self.input_size, bias=False)\n",
    "        \n",
    "        self.initWeights()\n",
    "        self.sigma = sigma\n",
    "        self.scale = nn.Parameter(torch.ones(self.input_size, requires_grad=True))\n",
    "\n",
    "    def initWeights(self):\n",
    "        nn.init.normal_(self.W.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.W.bias, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.U.weight, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.U.bias, mean=0.0, std=0.01)\n",
    "        nn.init.normal_(self.L.weight, mean=0.0, std=0.01)\n",
    "    \n",
    "    def calcLambdaK(self, h_t): \n",
    "      if(self.transform_fun == 'RELU'):\n",
    "        return torch.relu(h_t)\n",
    "      if self.transform_fun == 'SOFTPLUS':\n",
    "        return torch.log(1 + torch.exp(self.L(h_t)))\n",
    "      if self.transform_fun == 'SOFTPLUS_SCALE':\n",
    "        return self.scale * torch.log(1 + torch.exp(self.L(h_t)/self.scale))\n",
    "\n",
    "      raise Exception('Unsupported transform_fun')\n",
    "\n",
    "    def forward(self, events, times):\n",
    "        batch_size, batch_length, _ = events.shape\n",
    "\n",
    "        delta_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        o_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        c_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "        c_dash_seq = torch.zeros((batch_size, batch_length, self.hidden_size), device=cuda)\n",
    "\n",
    "        lambda_seq = torch.zeros(batch_size, batch_length, self.input_size, device=cuda)\n",
    "\n",
    "        h_t = torch.zeros((batch_size, self.hidden_size), device=cuda).float()\n",
    "        c_t = torch.zeros((batch_size, self.hidden_size), device=cuda).float()\n",
    "        c_dash = torch.zeros((batch_size, self.hidden_size),  device=cuda).float()\n",
    "\n",
    "        for event_idx in range(batch_length):\n",
    "          x = events[:, event_idx, :]\n",
    "        \n",
    "          outs = self.W(x) + self.U(h_t)\n",
    "\n",
    "          # 1 - input gate \n",
    "          # 2 - forget gate\n",
    "          # 3 - z gate\n",
    "          # 4 - output gate\n",
    "          # 5 - i_dash gate\n",
    "          # 6 - f_dash gate\n",
    "          # 7 - delta gate\n",
    "          i, f, z, o, i_dash, f_dash, delta = (\n",
    "                self.sigma(outs[:, :self.hidden_size]),\n",
    "                self.sigma(outs[:, self.hidden_size:self.hidden_size*2]), \n",
    "                2 * self.sigma(outs[:, self.hidden_size*2:self.hidden_size*3]) - 1, \n",
    "                self.sigma(outs[:, self.hidden_size*3:self.hidden_size*4]),\n",
    "                self.sigma(outs[:, self.hidden_size*4:self.hidden_size*5]), \n",
    "                self.sigma(outs[:, self.hidden_size*5:self.hidden_size*6]), \n",
    "                F.softplus(outs[:, self.hidden_size*6:self.hidden_size*7]), \n",
    "          )\n",
    "\n",
    "          c = f * c_t + i * z\n",
    "          c_dash = f_dash * c_dash + i_dash * z\n",
    "          t_now = times[:, event_idx].view(-1, 1)\n",
    "          t_next = times[:, event_idx + 1].view(-1, 1) \n",
    "          c_t = c_dash + (c - c_dash) * torch.exp(-delta * (t_next - t_now))\n",
    "          h_t = o * (2 * self.sigma(2 * c_t) - 1)\n",
    "          lambda_k = self.calcLambdaK(h_t)\n",
    "\n",
    "          c_seq[:, event_idx, :] = c\n",
    "          c_dash_seq[:, event_idx, :] = c_dash\n",
    "          o_seq[:, event_idx, :] = o\n",
    "          delta_seq[:, event_idx, :] = delta\n",
    "          lambda_seq[:, event_idx, :] = lambda_k\n",
    "\n",
    "        return c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq\n",
    "\n",
    "\n",
    "\n",
    "    def getLoss(self, events_ids, times, max_times, c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq):\n",
    "        batch_size, batch_length = events_ids.shape\n",
    "        original_loss = 0.\n",
    "\n",
    "        for ev in range(batch_length):\n",
    "            lambdas = lambda_seq[torch.arange(batch_size), ev, events_ids[:, ev]]\n",
    "            log_lambdas = torch.log(lambdas)\n",
    "            original_loss -= torch.sum(log_lambdas)\n",
    "\n",
    "        simulated_loss = 0.\n",
    "\n",
    "        trends = torch.rand((batch_size, batch_length), device=cuda) * max_times.view(-1, 1) # (1 x batch_size) to (batch_size x 1) to enable multiply\n",
    "        t_up = torch.searchsorted(times, trends)\n",
    "        I = torch.zeros((batch_size), device=cuda)\n",
    "        \n",
    "        for t_idx in range(batch_length):\n",
    "            T = trends[:, t_idx].view(-1,1)\n",
    "\n",
    "            idx = t_up[:, t_idx]\n",
    "            if torch.any(idx < 1):\n",
    "                continue\n",
    "            \n",
    "            t = times.gather(1, (idx-1).view(-1, 1))\n",
    "            \n",
    "            c_seq_x_dim = c_seq.shape[0]\n",
    "            c = c_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            c_dash = c_dash_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            delta = delta_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            o = o_seq[torch.arange(c_seq_x_dim), idx-1]\n",
    "            c_t = c_dash + (c - c_dash)*torch.exp(-delta * (T - t))\n",
    "            h_t = o * (2 * self.sigma(2 * c_t) - 1)\n",
    "            lambda_k =  self.calcLambdaK(h_t)\n",
    "            lambda_total = torch.sum(lambda_k, dim=1)\n",
    "            I += lambda_total * max_times / batch_length\n",
    "        \n",
    "\n",
    "        simulated_loss = torch.sum(I, dim=0)\n",
    "\n",
    "        loss = original_loss + simulated_loss\n",
    "\n",
    "        return loss / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = getPathDir()\n",
    "\n",
    "reload = False \n",
    "if reload: \n",
    "    last_epoch = 11\n",
    "    try:\n",
    "        net = torch.load(\"./social-interactions/{}/model_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, last_epoch))\n",
    "    except:\n",
    "        print(\"No saved network found. Starting from scratch\")\n",
    "        net = NNLSTM(n_types, hidden_size, transform_fun)\n",
    "else: \n",
    "    net = NNLSTM(n_types, hidden_size, transform_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyrDmJ2Pqk_F",
    "outputId": "570b8e3b-b831-411a-9e3a-c258da357649"
   },
   "outputs": [],
   "source": [
    "net.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJZqfpfFqkrE",
    "outputId": "54231319-ec52-4caf-cbc6-2017320b2afb"
   },
   "outputs": [],
   "source": [
    "next(net.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5zK4c_NomvX",
    "outputId": "a79d2340-2a3c-4fe4-f229-eb1418ed1da8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "losses = []\n",
    "train_time_start = timeit.default_timer()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    print(\"\\nEpoch:{}\".format(epoch+1), flush=True)\n",
    "    \n",
    "    batch_loss = []  \n",
    "    perm = torch.randperm(t_events.shape[0])\n",
    "\n",
    "    for batch_index in tqdm(range(0,  t_events.shape[0], batch_size), position=0, leave=True):\n",
    "        batch_begin = batch_index\n",
    "        batch_end = batch_index + batch_size\n",
    "\n",
    "        batch_events = t_events[perm][batch_begin:batch_end]\n",
    "        batch_events_ids = t_events_ids[perm][batch_begin:batch_end]\n",
    "        batch_times = t_times[perm][batch_begin:batch_end]\n",
    "        batch_max_times = t_times_max[perm][batch_begin:batch_end]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq = net.forward(batch_events, batch_times)\n",
    "        loss = net.getLoss(batch_events_ids, batch_times, batch_max_times, c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq)\n",
    "        batch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_batch_loss = mean(batch_loss)\n",
    "    print(mean_batch_loss)\n",
    "    if(math.isnan(mean_batch_loss) or not math.isfinite(mean_batch_loss)):\n",
    "      break\n",
    "    losses.append(mean_batch_loss)\n",
    "    torch.save(net, \"./social-interactions/{}/model_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, epoch+1))\n",
    "\n",
    "train_time_stop = timeit.default_timer()\n",
    "train_time = train_time_stop - train_time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjscZY0V1OSG",
    "outputId": "c1050b87-6f91-4e2e-e4de-168dcce85108"
   },
   "outputs": [],
   "source": [
    "print('Długość sekwencji: {}'.format(seq_len))\n",
    "print('Liczba rodzajów interakcji: {}'.format(n_types))\n",
    "print('Liczba epok: {}'.format(n_epoch))\n",
    "print('Rozmair porcji (batch): {}'.format(batch_size))\n",
    "print('Liczba ikrytych neuronów sieci: {}'.format(hidden_size))\n",
    "print('Funkcja transformująca: {}'.format(transform_fun))\n",
    "print('Czas trenowania: {}'.format(train_time))\n",
    "print('Czas przygotowania sekwencji: {}'.format(prep_time))\n",
    "print('Sztuczny zbiór danych: {}'.format(useSyntheticData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsIyYZ2zDF9f",
    "outputId": "35b37a25-bacd-4a8d-bb45-76a976f031ac"
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01yxTlscsYAu"
   },
   "outputs": [],
   "source": [
    "def singleSeqThinningAlgorithm(net, seq_events, seq_events_ids, seq_times):\n",
    "  n_events, n_types = seq_events.shape\n",
    "  c_seq, c_dash_seq, o_seq, delta_seq, lambda_seq = net.forward(seq_events.view(-1, n_events, n_types), seq_times.view(-1, n_events+1))\n",
    "\n",
    "  events_predicted = torch.zeros(n_events)\n",
    "  times_predicted = torch.zeros(n_events)\n",
    "  correct_pred = torch.zeros(n_events)\n",
    "\n",
    "  for i in range(n_events):\n",
    "    c = c_seq[:, i]\n",
    "    c_dash = c_dash_seq[:, i]\n",
    "    o = o_seq[:, i]\n",
    "    delta = delta_seq[:, i]\n",
    "    t = seq_times[i].item()\n",
    "    \n",
    "    c_max = torch.max(c, c_dash)\n",
    "    h_max = o * (2 * net.sigma(2 * c_max) - 1)\n",
    "    lambda_max = net.scale * torch.log(1 + torch.exp(net.L(h_max)/net.scale)).view(n_types)\n",
    "    lambda_max_total = torch.sum(lambda_max).item()\n",
    "\n",
    "    temp_t = t\n",
    "    lambda_total = math.inf\n",
    "\n",
    "    stop = False\n",
    "    stop_arr = []\n",
    "    while (not stop):  \n",
    "      delta_time = random.expovariate(lambda_max_total)\n",
    "      temp_t += delta_time\n",
    "\n",
    "      c_t = c_dash + (c - c_dash) * torch.exp(-delta * (temp_t - t))\n",
    "      h_t = o * (2 * net.sigma(2 * c_t) - 1)\n",
    "      lambda_k = net.scale * torch.log(1 + torch.exp(net.L(h_t)/net.scale)).view(n_types)\n",
    "\n",
    "      u = np.random.rand()\n",
    "      stop_arr = (u * lambda_max > lambda_k).nonzero().squeeze(1)\n",
    "      stop = len(stop_arr) > 0\n",
    "    \n",
    "    for _, ev in enumerate(torch.argsort(lambda_k, descending=True)):\n",
    "      ev = ev.item()\n",
    "      if(ev in stop_arr):\n",
    "        times_predicted[i] = temp_t\n",
    "        events_predicted[i] = ev\n",
    "        if ev == seq_events_ids[i].item():\n",
    "          correct_pred[i] = 1\n",
    "        break;\n",
    "\n",
    "  return times_predicted, events_predicted, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xIYC7PqRtKhP"
   },
   "outputs": [],
   "source": [
    "def getDetails(t_events, t_events_ids, t_times, seq_idx, seq_len):\n",
    "  return t_events[seq_idx, :seq_len], t_events_ids[seq_idx, :seq_len], t_times[seq_idx, :seq_len+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "797xxyCEqEzy"
   },
   "outputs": [],
   "source": [
    "def getAccByType(pred_events, true_events):\n",
    "  number_of_types = np.zeros(n_types)\n",
    "  number_of_true_pred_types = np.zeros(n_types)\n",
    "\n",
    "  for index, true_event in enumerate(true_events):\n",
    "    number_of_types[true_event] += 1\n",
    "    \n",
    "    if(true_event == pred_events[index]):\n",
    "      number_of_true_pred_types[true_event] += 1\n",
    "\n",
    "  for index, number_of_type in enumerate(number_of_types):\n",
    "    if(number_of_type == 0):\n",
    "      number_of_true_pred_types[index] = 1\n",
    "      number_of_types[index] = -1\n",
    "\n",
    "  acc_by_type = number_of_true_pred_types / number_of_types\n",
    "\n",
    "  return number_of_true_pred_types, number_of_types, acc_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVTzZMbSulGh"
   },
   "outputs": [],
   "source": [
    "def plotAccByType(acc_by_type):\n",
    "  seq_size = acc_by_type.shape[0]\n",
    "\n",
    "  acc_by_type = np.where(acc_by_type == -1, np.nan, acc_by_type)\n",
    "\n",
    "  plt.figure(figsize=(100,5))\n",
    "  plt.subplot(1,2,1)\n",
    "  for _type in range(n_types):\n",
    "      plt.plot(np.arange(0, seq_size, 1), acc_by_type[:,_type],'o', label=indexEventTypeSynMap(_type) if useSyntheticData else indexEventTypeMap(_type))\n",
    "\n",
    "  plt.legend(fontsize=14)\n",
    "  plt.ylabel(\"Dokładność predykcji\", fontsize=16)\n",
    "  plt.xlabel(\"Sekwencje\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsoyzEXrs9Gi"
   },
   "outputs": [],
   "source": [
    "n_test = test_events.shape[0]\n",
    "n_seq_max = test_events.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = getCuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Y65NVWCs-0n"
   },
   "outputs": [],
   "source": [
    "t_events_test, t_events_ids_test, t_times_test, t_times_max_test = toTensor(test_events, test_events_ids, test_times, test_times_max, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmkzhWaVqfmp"
   },
   "outputs": [],
   "source": [
    "def calcAccForAllSequences():\n",
    "    all_pred_times = torch.ones(n_test, n_seq_max) * -1 \n",
    "    acc_by_type = np.zeros((n_test,  n_types)) * -1\n",
    "    acc_arr = torch.zeros(n_test)\n",
    "\n",
    "    for idx in tqdm(range(n_test), position=0, leave=True):\n",
    "        seq_len = len(test_events[idx])\n",
    "        seq_events, seq_labels, times, embedded_events = getDetails(t_events, t_events_ids, t_times, idx, seq_len)\n",
    "        times_predicted, events_predicted, correct_pred  = singleSeqThinningAlgorithm(net, seq_events, seq_labels, times)\n",
    "        number_of_true_pred_types, number_of_types, acc_values_by_type = getAccByType(events_predicted, seq_labels)\n",
    "        acc_by_type[idx] = acc_values_by_type\n",
    "        acc_arr[idx] = torch.sum(correct_pred)/len(correct_pred)\n",
    "        all_pred_times[idx, :seq_len] = times_predicted\n",
    "    \n",
    "calcAccForAllSequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qQn17yWw45x"
   },
   "outputs": [],
   "source": [
    "plotAccByType(acc_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUjisu0GqhZ6"
   },
   "outputs": [],
   "source": [
    "acc_arr = acc_arr.numpy()\n",
    "all_pred_times = all_pred_times.numpy()\n",
    "events_predicted = events_predicted.numpy()\n",
    "\n",
    "print(\"Średnia dokładność predykcji przyszłych rodzajów zdarzeń: {:.4f}%\".format(np.mean(acc_arr)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMxMjOAwqiC0"
   },
   "outputs": [],
   "source": [
    "seq_avgs = np.zeros(n_test)\n",
    "seq_log_avgs = np.zeros(n_test)\n",
    "\n",
    "for seq in range(n_test):\n",
    "    seq_len = len(test_events[seq])\n",
    "    actual_time = test_times[seq, 1:seq_len]\n",
    "    actual_time = [i if i != 0 else 1 for i in actual_time]\n",
    "    predicted_time = all_pred_times[seq, 1:seq_len]\n",
    "    dT2 = (predicted_time - actual_time)**2\n",
    "    dT2_avg = np.sum(dT2)/seq_len\n",
    "    seq_avgs[seq] = dT2_avg\n",
    "    \n",
    "print(\"Pierwiastek z uśrednionego błędu średniokwadratowego wartości czasu dla {} sekwencji testowych: {}\".format(n_test, np.sqrt(np.mean(seq_avgs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccForAllEpoches():\n",
    "    for epoch in range(n_epoch):\n",
    "        try:\n",
    "            net = torch.load(\"gdrive/My Drive/social-interactions/{}/model_{}_{}_{}_{}_{}__{}.pt\".format(dir, seq_len, database, batch_size, hidden_size, windows_p, epoch+1))\n",
    "\n",
    "        except:\n",
    "            print(\"No saved network found. Starting from scratch\")\n",
    "            net = NNLSTM(n_types, hidden_size, transform_fun)\n",
    "\n",
    "        net.to(cuda)\n",
    "\n",
    "        all_pred_times = torch.ones(n_test, n_seq_max)*-1  # negative time means no event occurred\n",
    "        acc_by_type = np.zeros((n_test,  n_types)) * -1\n",
    "        acc_arr = torch.zeros(n_test)\n",
    "\n",
    "        for idx in tqdm(range(n_test), position=0, leave=True):\n",
    "          seq_len = len(test_events[idx])\n",
    "          seq_events, seq_labels, times = getDetails(t_events, t_events_ids, t_times, idx, seq_len)\n",
    "          times_predicted, events_predicted, correct_pred  = singleSeqThinningAlgorithm(net, seq_events, seq_labels, times)\n",
    "          number_of_true_pred_types, number_of_types, acc_values_by_type = getAccByType(events_predicted, seq_labels)\n",
    "\n",
    "          acc_by_type[idx] = acc_values_by_type\n",
    "          acc_arr[idx] = torch.sum(correct_pred)/len(correct_pred)\n",
    "          all_pred_times[idx, :seq_len] = times_predicted\n",
    "        acc_arr = acc_arr.numpy()\n",
    "        all_pred_times = all_pred_times.numpy()\n",
    "        events_predicted = events_predicted.numpy()\n",
    "\n",
    "        print(\"Średnia dokładność predykcji przyszłych rodzajów zdarzeń dla {}: {:.4f}%\".format(epoch+1, np.mean(acc_arr)*100))\n",
    "        \n",
    "calcAccForAllEpoches()        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NN nethealth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
